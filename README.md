# ğŸ§  Neural Network Visualizer - MLP From Scratch

**Profesyonel, interaktif sinir aÄŸÄ± gÃ¶rselleÅŸtirme uygulamasÄ±**

Python ve NumPy kullanÄ±larak sÄ±fÄ±rdan yazÄ±lmÄ±ÅŸ tek katmanlÄ± ve Ã§ok katmanlÄ± sinir aÄŸÄ± algoritmalarÄ±nÄ± gÃ¶rselleÅŸtiren modern masaÃ¼stÃ¼ uygulamasÄ±.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![NumPy](https://img.shields.io/badge/NumPy-1.24+-green.svg)
![CustomTkinter](https://img.shields.io/badge/CustomTkinter-5.2+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ Ä°Ã§indekiler

- [Ã–zellikler](#-Ã¶zellikler)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [Algoritmalar](#-algoritmalar)
- [Ekran GÃ¶rÃ¼ntÃ¼leri](#-ekran-gÃ¶rÃ¼ntÃ¼leri)
- [Teknoloji Stack](#-teknoloji-stack)
- [KatkÄ±da Bulunma](#-katkÄ±da-bulunma)

## âœ¨ Ã–zellikler

### ğŸ¯ Ä°nteraktif Veri Ekleme
- Fare ile doÄŸrudan grafik Ã¼zerine tÄ±klayarak veri noktalarÄ± ekleyin
- Ã‡oklu sÄ±nÄ±f desteÄŸi (maksimum 6 sÄ±nÄ±f)
- Dinamik sÄ±nÄ±f yÃ¶netimi

### ğŸ¤– ÃœÃ§ FarklÄ± Algoritma
1. **Single-Layer Perceptron**: DoÄŸrusal olarak ayrÄ±labilir problemler iÃ§in
2. **Single-Layer Delta Rule (Adaline)**: MSE minimize eden Widrow-Hoff Ã¶ÄŸrenme kuralÄ±
3. **Multi-Layer Perceptron (MLP)**: Backpropagation ile eÄŸitilen derin sinir aÄŸÄ±

### ğŸ¨ CanlÄ± GÃ¶rselleÅŸtirme
- **EÄŸitim Sekmesi**: EÄŸitim sÄ±rasÄ±nda karar sÄ±nÄ±rlarÄ±nÄ±n canlÄ± animasyonu
- **Test Sekmesi**: Test verisi Ã¼zerinde model performansÄ±
- **Hata GrafiÄŸi**: Epoch'lara gÃ¶re loss deÄŸiÅŸimi

### âš™ï¸ Esnek Hiperparametre KontrolÃ¼
- Ã–zelleÅŸtirilebilir katman mimarisi
- Aktivasyon fonksiyonu seÃ§imi (ReLU, Tanh, Sigmoid, Softmax)
- Ã–ÄŸrenme oranÄ±, epoch sayÄ±sÄ±, batch size ayarlarÄ±
- L2 Regularization desteÄŸi
- Test/Train split oranÄ±

### ğŸ”¬ SÄ±fÄ±rdan YazÄ±lmÄ±ÅŸ Algoritmalar
- **Backpropagation**: Chain rule ile manuel gradyan hesaplama
- **Aktivasyon FonksiyonlarÄ±**: ReLU, Tanh, Sigmoid ve tÃ¼revleri
- **Loss Fonksiyonu**: Cross-Entropy Loss
- **Optimization**: Mini-batch Gradient Descent
- **Regularization**: L2 (Weight Decay)

## ğŸš€ Kurulum

### Gereksinimler
- Python 3.8 veya Ã¼zeri
- pip paket yÃ¶neticisi

### AdÄ±m 1: Depoyu KlonlayÄ±n
```bash
git clone https://github.com/ensaryesir/MLP-From-Scratch-GUI.git
cd MLP-From-Scratch-GUI
```

### AdÄ±m 2: BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
pip install -r requirements.txt
```

### AdÄ±m 3: UygulamayÄ± Ã‡alÄ±ÅŸtÄ±rÄ±n
```bash
python main.py
```

## ğŸ“– KullanÄ±m

### 1ï¸âƒ£ Veri Ekleme
1. SaÄŸ panelde istediÄŸiniz sÄ±nÄ±fÄ± seÃ§in
2. Sol taraftaki **EÄŸitim (Train)** grafiÄŸine fare ile tÄ±klayarak veri noktalarÄ± ekleyin
3. Gerekirse **+ Class** butonu ile yeni sÄ±nÄ±flar ekleyin

### 2ï¸âƒ£ Model SeÃ§imi ve Ayarlama
1. **Model SeÃ§imi**: Perceptron, Delta Rule veya MLP seÃ§in
2. **Hiperparametreler**: 
   - MLP iÃ§in katman mimarisini ayarlayÄ±n (Ã¶rn: `2,5,3`)
   - Aktivasyon fonksiyonlarÄ±nÄ± seÃ§in (Ã¶rn: `relu,softmax`)
   - Ã–ÄŸrenme oranÄ±, epoch sayÄ±sÄ± ve diÄŸer parametreleri ayarlayÄ±n

### 3ï¸âƒ£ EÄŸitim
1. **START TRAINING** butonuna tÄ±klayÄ±n
2. EÄŸitim sÄ±rasÄ±nda:
   - Karar sÄ±nÄ±rlarÄ±nÄ±n nasÄ±l oluÅŸtuÄŸunu izleyin
   - **Hata GrafiÄŸi** sekmesinde loss deÄŸiÅŸimini takip edin
3. EÄŸitim tamamlandÄ±ÄŸÄ±nda:
   - **Test** sekmesine geÃ§erek model performansÄ±nÄ± gÃ¶rÃ¼n
   - Test accuracy deÄŸerini kontrol edin

### 4ï¸âƒ£ Veri Temizleme
- **Clear Data** butonu ile tÃ¼m veri noktalarÄ±nÄ± silebilirsiniz

## ğŸ“ Proje YapÄ±sÄ±

```
MLP-From-Scratch-GUI/
â”œâ”€â”€ main.py                      # Ana uygulama orkestratÃ¶rÃ¼
â”œâ”€â”€ requirements.txt             # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ README.md                    # Proje dokÃ¼mantasyonu
â”‚
â”œâ”€â”€ algorithms/                  # Sinir aÄŸÄ± algoritmalarÄ±
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ single_layer.py         # Perceptron ve Delta Rule
â”‚   â””â”€â”€ mlp.py                  # Multi-Layer Perceptron + Backpropagation
â”‚
â”œâ”€â”€ gui/                         # KullanÄ±cÄ± arayÃ¼zÃ¼ bileÅŸenleri
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ control_panel.py        # Kontrol paneli widget'larÄ±
â”‚   â””â”€â”€ visualization_frames.py # GÃ¶rselleÅŸtirme sekmeleri
â”‚
â””â”€â”€ utils/                       # YardÄ±mcÄ± modÃ¼ller
    â”œâ”€â”€ __init__.py
    â””â”€â”€ data_handler.py         # Veri yÃ¶netimi
```

## ğŸ§® Algoritmalar

### Perceptron
```
GÃ¼ncelleme KuralÄ±: w = w + Î· * (y_true - y_pred) * x
```
- Step aktivasyon fonksiyonu
- Binary ve multi-class classification desteÄŸi

### Delta Rule (Adaline)
```
Loss: MSE = (1/n) * Î£(y_true - y_pred)Â²
Gradient: âˆ‚L/âˆ‚w = -(2/n) * X^T * (y_true - y_pred)
```
- Linear aktivasyon fonksiyonu
- Gradient descent ile eÄŸitim

### Multi-Layer Perceptron (MLP)

**Forward Propagation:**
```
Z^[l] = A^[l-1] * W^[l] + b^[l]
A^[l] = activation(Z^[l])
```

**Backpropagation:**
```
dZ^[L] = A^[L] - Y  (son katman)
dW^[l] = (1/m) * A^[l-1]^T * dZ^[l]
db^[l] = (1/m) * Î£(dZ^[l])
dZ^[l-1] = dZ^[l] * W^[l]^T âŠ™ g'(Z^[l-1])
```

**Aktivasyon FonksiyonlarÄ±:**
- **ReLU**: `f(x) = max(0, x)`, `f'(x) = 1 if x > 0 else 0`
- **Tanh**: `f(x) = tanh(x)`, `f'(x) = 1 - tanhÂ²(x)`
- **Sigmoid**: `f(x) = 1/(1+e^-x)`, `f'(x) = f(x)(1-f(x))`
- **Softmax**: `f(x_i) = e^x_i / Î£e^x_j` (multi-class iÃ§in)

**Loss Fonksiyonu:**
```
Cross-Entropy: L = -(1/m) * Î£ Î£ y_true * log(y_pred)
L2 Regularization: L_reg = (Î»/2m) * Î£||W||Â²
```

## ğŸ“¸ Ekran GÃ¶rÃ¼ntÃ¼leri

*UygulamayÄ± Ã§alÄ±ÅŸtÄ±rarak interaktif deneyimi kendiniz yaÅŸayÄ±n!*

### Ã–zellikler:
- âœ… Modern dark mode arayÃ¼z
- âœ… Renkli karar sÄ±nÄ±rlarÄ±
- âœ… Real-time animasyonlar
- âœ… Profesyonel grafikler

## ğŸ› ï¸ Teknoloji Stack

- **Python 3.8+**: Ana programlama dili
- **NumPy**: SayÄ±sal hesaplamalar ve matris iÅŸlemleri
- **Matplotlib**: Bilimsel gÃ¶rselleÅŸtirme
- **CustomTkinter**: Modern GUI framework

### âš ï¸ YasaklÄ± KÃ¼tÃ¼phaneler
Bu proje **eÄŸitim amaÃ§lÄ±** olduÄŸundan, aÅŸaÄŸÄ±daki kÃ¼tÃ¼phaneler **KESÄ°NLÄ°KLE KULLANILMAMIÅTIR**:
- âŒ scikit-learn
- âŒ TensorFlow
- âŒ PyTorch
- âŒ Keras

TÃ¼m algoritmalar sÄ±fÄ±rdan NumPy ile yazÄ±lmÄ±ÅŸtÄ±r.

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen ÅŸu adÄ±mlarÄ± izleyin:

1. Projeyi fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Branch'inizi push edin (`git push origin feature/AmazingFeature`)
5. Pull Request aÃ§Ä±n

## ğŸ“ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

**Ensar YeÅŸir**
- GitHub: [@ensaryesir](https://github.com/ensaryesir)

## ğŸ™ TeÅŸekkÃ¼rler

Bu proje, makine Ã¶ÄŸrenmesi ve sinir aÄŸlarÄ± derslerinde Ã¶ÄŸrenilen teorik bilgilerin pratik uygulamasÄ±dÄ±r.

---

â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!

**Keyifli kodlamalar! ğŸš€**